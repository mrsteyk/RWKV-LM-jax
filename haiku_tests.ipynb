{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "COMBINE_BYTES = 130*1024*1024\n",
    "os.environ[\"XLA_FLAGS\"] = f\"--xla_gpu_simplify_all_fp_conversions --xla_gpu_all_reduce_combine_threshold_bytes={COMBINE_BYTES}\"\n",
    "os.environ[\"NVIDIA_TF32_OVERRIDE\"] = \"0\" # IDFK how this could help on Pascal\n",
    "\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jmp\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: config dataclass\n",
    "NUM_LAYERS = 24\n",
    "MP = 'f32'\n",
    "# MP = 'f16'\n",
    "# MP = 'bf16'\n",
    "\n",
    "def _forward(x):\n",
    "    a = model.RWKV(num_layers=NUM_LAYERS, vocab_size=50277, n_embd=1024, dim_att=1024, dim_ffn=1024*4)\n",
    "    return a(x)\n",
    "\n",
    "def _forwardb(x):\n",
    "    a = model.RWKV(num_layers=NUM_LAYERS, vocab_size=50277, n_embd=1024, dim_att=1024, dim_ffn=1024*4)\n",
    "    a = jax.vmap(a)\n",
    "    return a(x)\n",
    "\n",
    "# policy = jmp.get_policy(f'p={MP},c={MP},o={MP}')\n",
    "# policy_wkv = jmp.get_policy(f'p=f32,c=f32,o={MP}')\n",
    "# hk.mixed_precision.set_policy(_forward, policy)\n",
    "# hk.mixed_precision.set_policy(model.RWKV, policy)\n",
    "# hk.mixed_precision.set_policy(model.WKV, policy_wkv)\n",
    "# hk.mixed_precision.set_policy(model.WKV_n, policy_wkv)\n",
    "# hk.mixed_precision.set_policy(model.WKV_nn, policy_wkv)\n",
    "# ---\n",
    "# policy_64 = jmp.get_policy(f'p=f64,c=f64,o=f64')\n",
    "# hk.mixed_precision.set_policy(_forward, policy_64)\n",
    "# hk.mixed_precision.set_policy(model.RWKV, policy_64)\n",
    "# hk.mixed_precision.set_policy(model.WKV, policy_64)\n",
    "# hk.mixed_precision.set_policy(model.WKV_n, policy_64)\n",
    "\n",
    "dummy_x = jnp.ones((1024), dtype=int)\n",
    "rng_key = jax.random.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.numpy import load_file\n",
    "import torch\n",
    "\n",
    "#sd = load_file(\"../../RWKV-LM-deepspeed/RWKV-v4neo/RWKV-4-Pile-430M-20220808-8066.safetensors\")\n",
    "sd = torch.load(\"/home/mrsteyk/projects/RWKV-LM/RWKV-v4neo/RWKV-4-Pile-430M-20220808-8066.pth\", map_location='cpu')\n",
    "sd = {k: v.float().numpy() for k,v in sd.items()}\n",
    "if MP.endswith('16'):\n",
    "    sd = {k: jnp.array(v, dtype=jnp.float16 if MP == 'f16' else jnp.bfloat16) for k,v in sd.items()}\n",
    "\n",
    "# I am mentally ill, you cannot :clown: upon me\n",
    "head = {\"w\": jax.device_put(sd[\"head.weight\"].T)}\n",
    "ln_out = {\"scale\": jax.device_put(sd[\"ln_out.weight\"]), \"offset\": jax.device_put(sd[\"ln_out.bias\"])}\n",
    "emb = {\"embeddings\": jax.device_put(sd[\"emb.weight\"])} # opt: put on jax.device(\"cpu\")[0]?\n",
    "ln0 = {\"scale\": jax.device_put(sd[\"blocks.0.ln0.weight\"]), \"offset\": jax.device_put(sd[\"blocks.0.ln0.bias\"])}\n",
    "\n",
    "# Remember, no ~~Russians~~:clown: (how long until this old joke gets old again, ngl kinda miss those days even though scene's dead)\n",
    "hsd = {\"rwkv/head\": head, \"rwkv/ln0\": ln0, \"rwkv/emb\": emb, \"rwkv/ln_out\": ln_out}\n",
    "for i in range(NUM_LAYERS):\n",
    "    hsd[f\"rwkv/block_{i}/ln1\"] = {\"scale\": jax.device_put(sd[f\"blocks.{i}.ln1.weight\"]), \"offset\": jax.device_put(sd[f\"blocks.{i}.ln1.bias\"])}\n",
    "    hsd[f\"rwkv/block_{i}/att\"] = {\n",
    "        \"time_first\": jax.device_put(sd[f\"blocks.{i}.att.time_first\"]),\n",
    "        \"time_decay\": jax.device_put(sd[f\"blocks.{i}.att.time_decay\"]),\n",
    "        \"time_mix_k\": jax.device_put(sd[f\"blocks.{i}.att.time_mix_k\"][0]),\n",
    "        \"time_mix_v\": jax.device_put(sd[f\"blocks.{i}.att.time_mix_v\"][0]),\n",
    "        \"time_mix_r\": jax.device_put(sd[f\"blocks.{i}.att.time_mix_r\"][0]),\n",
    "    }\n",
    "    hsd[f\"rwkv/block_{i}/att/key\"] = {\"w\": jax.device_put(sd[f\"blocks.{i}.att.key.weight\"].T)}\n",
    "    hsd[f\"rwkv/block_{i}/att/value\"] = {\"w\": jax.device_put(sd[f\"blocks.{i}.att.value.weight\"].T)}\n",
    "    hsd[f\"rwkv/block_{i}/att/receptance\"] = {\"w\": jax.device_put(sd[f\"blocks.{i}.att.receptance.weight\"].T)}\n",
    "    hsd[f\"rwkv/block_{i}/att/output\"] = {\"w\": jax.device_put(sd[f\"blocks.{i}.att.output.weight\"].T)}\n",
    "\n",
    "    hsd[f\"rwkv/block_{i}/ln2\"] = {\"scale\": jax.device_put(sd[f\"blocks.{i}.ln2.weight\"]), \"offset\": jax.device_put(sd[f\"blocks.{i}.ln2.bias\"])}\n",
    "    hsd[f\"rwkv/block_{i}/ffn\"] = {\n",
    "        \"time_mix_k\": jax.device_put(sd[f\"blocks.{i}.ffn.time_mix_k\"][0]),\n",
    "        \"time_mix_r\": jax.device_put(sd[f\"blocks.{i}.ffn.time_mix_r\"][0]),\n",
    "    }\n",
    "    hsd[f\"rwkv/block_{i}/ffn/key\"] = {\"w\": jax.device_put(sd[f\"blocks.{i}.ffn.key.weight\"].T)}\n",
    "    hsd[f\"rwkv/block_{i}/ffn/value\"] = {\"w\": jax.device_put(sd[f\"blocks.{i}.ffn.value.weight\"].T)}\n",
    "    hsd[f\"rwkv/block_{i}/ffn/receptance\"] = {\"w\": jax.device_put(sd[f\"blocks.{i}.ffn.receptance.weight\"].T)}\n",
    "\n",
    "# hsd = {k: {kk: vv.astype(jnp.float32) for kk,vv in v.items()} for k,v in hsd.items()}\n",
    "\n",
    "# print(sd[\"blocks.0.att.time_decay\"], sd[\"blocks.0.att.time_first\"])\n",
    "\n",
    "del head, ln_out, emb, ln0\n",
    "del sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling fn\n",
      "fn compiled in 6.02723s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Array([ -1.2497783, -17.84948  ,  -1.4722643, ...,  -4.042045 ,\n",
       "         -4.2051826,  -2.6865644], dtype=float32),\n",
       " Array([7.5581676e-04, 4.6693666e-11, 6.0505077e-04, ..., 4.6318066e-05,\n",
       "        3.9346014e-05, 1.7965032e-04], dtype=float32),\n",
       " Array([ True,  True,  True], dtype=bool),\n",
       " Array([ True,  True,  True], dtype=bool),\n",
       " Array([ True,  True,  True], dtype=bool),\n",
       " Array([ True,  True,  True], dtype=bool))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from jax.config import config\n",
    "# config.update(\"jax_debug_nans\", True)\n",
    "# config.update(\"jax_debug_infs\", True)\n",
    "# config.update(\"jax_disable_jit\", True)\n",
    "# config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "a = hk.transform(_forward)\n",
    "\n",
    "# CUDA kernel with my safetensors\n",
    "# tensor([ -1.2363,    -17.8281,    -1.4609,  ...,    -4.0469, \n",
    "#          -4.2070,    -2.6816], device='cuda:0') torch.Size([50277])\n",
    "# CUDA kernel, run 2 with OG checkpoint???\n",
    "# tensor([ -1.2497251, -17.8494244,  -1.4722213,  ...,  -4.0420585,\n",
    "#          -4.2051859,  -2.6865544], device='cuda:0') torch.Size([50277])\n",
    "# CUDA kernel, OG, no fastmath no opts.\n",
    "# tensor([ -1.2497274876, -17.8494243622,  -1.4722241163,  ...,\n",
    "#          -4.0420608521,  -4.2051901817,  -2.6865549088], device='cuda:0') torch.Size([50277])\n",
    "# PyTorch port - ~29.5s no jit, ~4.5s with jit not disabled, ~4s with actual JIT (~224.364s to compile)\n",
    "# Array ([ -1.249722,  -17.849419,  -1.472222, ...,   -4.042059,\n",
    "#          -4.205187,   -2.686554], dtype=float32)\n",
    "# vmap+scan - >60s, ~5 to ~7s with jit not disabled, ~2s with actual JIT (~13s to compile)\n",
    "# Array ([ -1.2497513, -17.849443 , -1.4722407, ...,  -4.042043 ,\n",
    "#          -4.2051764,  -2.6865528], dtype=float32)\n",
    "# scan only (batched C) - >60s, IDKs, <1s with actual JIT (~9.8s to compile)\n",
    "# Array ([ -1.2497783,  -17.84948  , -1.4722643, ...,  -4.042045 ,\n",
    "#          -4.2051826,  -2.6865644], dtype=float32),\n",
    "C = 1024 * 1\n",
    "# C = 4097 * 2 # OAI is a meme\n",
    "# C = 8\n",
    "x = jax.device_put(jnp.array([0]*C))\n",
    "print('compiling fn')\n",
    "start = time.time()\n",
    "# apply_jit = jax.jit(a.apply, backend='cpu')\n",
    "apply_jit = jax.jit(a.apply)\n",
    "i = apply_jit(hsd, rng_key, x=x)[-1]\n",
    "print(f\"fn compiled in {time.time() - start:.06}s\")\n",
    "i = apply_jit(hsd, rng_key, x=x)[-1]\n",
    "# i = a.apply(hsd, rng_key, x=[0]*C)[-1]\n",
    "# %timeit apply_jit(hsd, rng_key, x=x)\n",
    "# print(jax.make_jaxpr(apply_jit)(hsd, rng_key, x=x))\n",
    "si = jax.nn.softmax(i)\n",
    "(\n",
    "    i, si,\n",
    "    jnp.isclose(i[:3], jnp.array([-1.2497251034, -17.8494243622,  -1.4722212553]), rtol=1e-4), jnp.isclose(i[-3:], jnp.array([-4.0420584679,  -4.2051858902,  -2.6865544319]), rtol=1e-4),\n",
    "    jnp.isclose(si[:3], jnp.array([7.5585511513e-04, 4.6696126133e-11, 6.0507573653e-04]), rtol=1e-4), jnp.isclose(si[-3:], jnp.array([4.6317345550e-05, 3.9345799451e-05, 1.7965181905e-04]), rtol=1e-4)\n",
    ")\n",
    "# apply_jitb = jax.vmap(apply_jit, in_axes=(None, None, 0), out_axes=0)\n",
    "# xb = jnp.array([x]*3)\n",
    "# %timeit apply_jitb(hsd, rng_key, x=xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from jax.config import config\n",
    "# config.update(\"jax_debug_nans\", True)\n",
    "# config.update(\"jax_debug_infs\", True)\n",
    "# config.update(\"jax_disable_jit\", True)\n",
    "# config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "ab = hk.transform(_forwardb)\n",
    "B = 2\n",
    "C = 1024 * 4\n",
    "# C = 8\n",
    "x = jax.device_put(jnp.array([[0]*C]*B))\n",
    "print('compiling fn')\n",
    "start = time.time()\n",
    "# apply_jit = jax.jit(a.apply, backend='cpu')\n",
    "apply_jitb = jax.jit(ab.apply)\n",
    "i = apply_jitb(hsd, rng_key, x=x)[-1]\n",
    "print(f\"fn compiled in {time.time() - start:.06}s\")\n",
    "%timeit apply_jitb(hsd, rng_key, x=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.config import config\n",
    "config.update(\"jax_debug_nans\", True)\n",
    "config.update(\"jax_debug_infs\", True)\n",
    "config.update(\"jax_disable_jit\", True)\n",
    "\n",
    "a = hk.transform(_forward)\n",
    "\n",
    "i = a.init(rng=rng_key, x=dummy_x)\n",
    "print(\"---\")\n",
    "i, a.apply(i, rng_key, x=dummy_x)\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([0, 1, 2, 3, 4], dtype=int32), Array([0, 1, 2, 3, 4], dtype=int32))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.arange(5), jnp.array([0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0, 1, 2, 3, 4]], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# why does it need `,`\n",
    "jnp.arange(5)[jnp.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1, 4],\n",
       "       [2, 5],\n",
       "       [3, 6]], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.array([[1, 2, 3], [4, 5, 6]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[1],\n",
       "        [2],\n",
       "        [3]], dtype=int32),\n",
       " Array([[1],\n",
       "        [2],\n",
       "        [3]], dtype=int32),\n",
       " (3, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time decay/first are monotonous arrays\n",
    "a = jnp.array([1,2,3])\n",
    "a = a[:,jnp.newaxis]\n",
    "aa = jnp.expand_dims(a, 1)\n",
    "aa, a, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[1],\n",
       "        [2],\n",
       "        [3]], dtype=int32),\n",
       " Array([[4],\n",
       "        [5],\n",
       "        [6]], dtype=int32),\n",
       " Array([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]], dtype=int32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jnp.concatenate(jnp.array([[[0, 1, 2]], [[3, 4, 5]]]), axis=0)\n",
    "a = jnp.array([1, 2, 3])[:, jnp.newaxis]\n",
    "b = jnp.array([4, 5, 6])[:, jnp.newaxis]\n",
    "a, b, jnp.concatenate([a, b], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[1],\n",
       "        [2],\n",
       "        [3]], dtype=int32),\n",
       " Array([[-2, -1,  0]], dtype=int32),\n",
       " Array([[-2, -1,  0],\n",
       "        [-4, -2,  0],\n",
       "        [-6, -3,  0]], dtype=int32),\n",
       " Array([[-2, -1,  0,  1],\n",
       "        [-4, -2,  0,  2],\n",
       "        [-6, -3,  0,  3]], dtype=int32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 3 + 1\n",
    "b = jnp.arange(-(T-2), 1)[jnp.newaxis, :]\n",
    "# this should be ok for the operation?\n",
    "matrix = jnp.concatenate([a*b, a], axis=1)\n",
    "a, b, a*b, matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564 µs ± 5.91 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def wkv(w, u, k, v):\n",
    "    T, C = k.shape\n",
    "    time_curve = jnp.arange(-T+2, 1)[jnp.newaxis, ...]\n",
    "    k, v = map(jnp.array, [[k], [v]])\n",
    "    w = -jnp.exp(w)\n",
    "    ek = jnp.exp(k.transpose((0, 2, 1)))\n",
    "    ekv = ek * v.transpose((0, 2, 1))\n",
    "    ew_time = jnp.expand_dims(jnp.exp(w), 1) * time_curve\n",
    "    time_w = jnp.concatenate([ew_time, jnp.expand_dims(u, 1)], axis=1)\n",
    "    w = jnp.expand_dims(jnp.exp(time_w), 1)\n",
    "\n",
    "    # print(time_w.shape, ew_time.shape, time_w, ew_time)\n",
    "    # print(ew_time.shape, time_w.shape, w.shape, ekv.shape, ek.shape)\n",
    "\n",
    "    def pad(x): return jnp.pad(x, [(0, 0), (0, 0), (T-1, 0)])\n",
    "\n",
    "    wkv = jax.lax.conv_general_dilated(pad(ekv), w, (1,), [(\n",
    "        0, 0)], dimension_numbers=('NCW', 'OIW', 'NCW'), feature_group_count=C)\n",
    "    wk = jax.lax.conv_general_dilated(pad(ek), w, (1,), [(\n",
    "        0, 0)], dimension_numbers=('NCW', 'OIW', 'NCW'), feature_group_count=C)\n",
    "    return (wkv / wk).transpose(0, 2, 1)[0].T\n",
    "\n",
    "%timeit wkv(jnp.array([1. , 2., 3.]), jnp.array([0.1, 0.2, 0.3]), jnp.array([[11, 22, 33], [44, 55, 66], [77, 88, 99]], dtype=jnp.float32), jnp.array([[11, 22, 33], [44, 55, 66], [77, 88, 99]], dtype=jnp.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638 µs ± 51.4 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model.WKV(jnp.array([1. , 2., 3.]), jnp.array([0.1, 0.2, 0.3]), jnp.array([[11, 22, 33], [44, 55, 66], [77, 88, 99]], dtype=jnp.float32), jnp.array([[11, 22, 33], [44, 55, 66], [77, 88, 99]], dtype=jnp.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688 µs ± 56.9 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "if wkv_jit is None:\n",
    "    wkv_jit = jax.jit(model.WKV_nn)\n",
    "    wkv_jit(jnp.array([1. , 2., 3.]), jnp.array([0.1, 0.2, 0.3]), jnp.array([[11, 22, 33], [44, 55, 66], [77, 88, 99]], dtype=jnp.float32), jnp.array([[11, 22, 33], [44, 55, 66], [77, 88, 99]], dtype=jnp.float32))\n",
    "%timeit wkv_jit(jnp.array([1. , 2., 3.]), jnp.array([0.1, 0.2, 0.3]), jnp.array([[11, 22, 33], [44, 55, 66], [77, 88, 99]], dtype=jnp.float32), jnp.array([[11, 22, 33], [44, 55, 66], [77, 88, 99]], dtype=jnp.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ 1,  2,  3],\n",
       "        [11, 22, 33]],\n",
       "\n",
       "       [[ 4,  5,  6],\n",
       "        [44, 55, 66]]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = jnp.array([[1, 2, 3], [4, 5, 6]])\n",
    "v = jnp.array([[11, 22, 33], [44, 55, 66]])\n",
    "jnp.concatenate([k[:, jnp.newaxis], v[:, jnp.newaxis]], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "108a77ccb50483248237e4437e3c4c648b04e6f2ff2fc5096b4500deb5d70dcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
